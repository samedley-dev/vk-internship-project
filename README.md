# VK Internship Project

## Описание

Данная директория содержит решение задачи бинарной классифицации временных рядов.

## Структура директории решения до запуска всех скриптов

```plaintext
vk-internship-project/
├── models/
│   └── (папка пустая)
├── notebooks/
│   └── eda.ipynb
├── input/
│   ├── train.parquet
│   └── test.parquet
├── scripts/
│   ├── utils.py
│   ├── feature_engineering.py
│   ├── model_training.py
│   └── generate_submission.py
└── requirements.txt
```

### Папка models/
  - Директория для хранения обученных моделей. После выполнения скрипта `model_training.py`, обученная модель будет сохранена в эту папку.
  
### Папка notebooks/
  - `eda.ipynb`: Jupyter Notebook для проведения разведочного анализа данных (EDA). Используйте его для понимания структуры и особенностей данных.

### Папка input/
  - `train.parquet`: Исходные тренировочные данные для обучения модели.
  - `test.parquet`: Исходные тестовые данные для создания предсказаний.

### Папка scripts/
  - `utils.py`: Файл с вспомогательными функциями, которые могут использоваться в других скриптах проекта.
  - `feature_engineering.py`: Скрипт для генерации новых признаков на основе исходных данных. **Этот скрипт запускается первым**. Он обрабатывает данные из `../input/train.parquet` и `../input/test.parquet`, и сохраняет обработанные данные для дальнейшего использования.
  - `model_training.py`: Скрипт для обучения модели. **Запускается вторым**. Использует обработанные данные, созданные скриптом `feature_engineering.py`, и тренирует модель. Обученная модель сохраняется в папку `../models/`.
  - `generate_submission.py`: Скрипт для создания файла предсказаний. **Запускается последним**. Он использует обученную модель для предсказания на тестовых данных и генерирует файл `submission.csv`, который будет оценен.

### Файл с необходимыми зависимости
  Файл requirements.txt содержит список зависимостей Python, необходимых для работы проекта.


## Описание скриптов

### utils.py

Этот скрипт содержит полезные функции для обработки данных.
  - `filter_nans(df)`: Эта функция обрабатывает пропуски в данных. Она проверяет наличие пропущенных значений в каждом столбце DataFrame. Если в каком-либо столбце есть пропуски, они заполняются средним значением этого столбца.

### feature_engineering.py

Этот скрипт отвечает за генерацию новых признаков на основе исходных данных и создание обработанных датасетов.
  - **Основные функции**:
    - `calculate_date(date)`: Преобразует дату в количество дней с 1 января 1970 года.
    - `get_start_date(dates)`: Возвращает первую дату из списка.
    - `get_end_date(dates)`: Возвращает последнюю дату из списка.
    - `calculate_duration(dates)`: Вычисляет продолжительность между первой и последней датами в списке.
    - `calculate_mean_value(values)`: Вычисляет среднее значение списка.
    - `calculate_min_value(values)`: Находит минимальное значение в списке.
    - `calculate_max_value(values)`: Находит максимальное значение в списке.
    - `calculate_std_dev(values)`: Вычисляет стандартное отклонение для списка значений.
    - `calculate_median_value(values)`: Вычисляет медиану списка значений.
    - `count_values(values)`: Возвращает количество значений в списке.
    - `calculate_cumulative_change(values)`: Рассчитывает суммарное изменение значений (разности между последовательными значениями).
    - `calculate_iqr(values)`: Вычисляет межквартильный размах (IQR).
    - `calculate_skewness(values)`: Рассчитывает коэффициент асимметрии списка значений.
    - `calculate_kurtosis(values)`: Рассчитывает эксцесс (коэффициент "пиковой" формы распределения).
    - `generate_features(df)`: Основная функция для генерации новых признаков. Она создает новые столбцы в DataFrame на основе предоставленных функций.

  - **Процесс работы**:
    - Данные загружаются из файлов `train.parquet` и `test.parquet`.
    - Функция `generate_features` создает новые признаки, такие как продолжительность, средние значения, стандартное отклонение, медиана и другие метрики для каждого экземпляра данных.
    - Обработанные данные сохраняются в файлы `train_processed.parquet` и `test_processed.parquet`.

### model_training.py

Этот скрипт используется для обучения модели с использованием обработанных данных.
  - **Основные функции**:
    - `catboost_clf()`: Создаёт и возвращает экземпляр модели `CatBoostClassifier`, которая используется для классификации.
    - `feature_target_split(df)`: Разделяет DataFrame на признаки (X) и целевую переменную (y), предварительно обрабатывая пропущенные значения с помощью функции `filter_nans` из модуля `utils.py`. Из набора данных исключаются столбцы `id` и `y`.
    - `train_save_model(model, df, path)`: Обучает переданную модель на данных и сохраняет её по указанному пути. Модель обучается на данных, обработанных функцией `feature_target_split`.

  - **Процесс работы**:
    - Обработанные тренировочные данные загружаются из файла `train_processed.parquet`.
    - Создаётся и обучается модель `CatBoostClassifier` на обработанных данных.
    - Обученная модель сохраняется в директории `../models/` под именем `catboost_clf.cbm`.

### generate_submission.py

Этот скрипт используется для генерации файла с предсказаниями на основе обученной модели.
  - **Основные функции**:
    - `catboost_clf()`: Создаёт экземпляр модели `CatBoostClassifier`.
    - `feature_split(df)`: Подготавливает данные для предсказания, фильтруя пропущенные значения с помощью функции `filter_nans` и удаляя столбец `id`.
    - `submit(df)`: Использует обученную модель для создания предсказаний. Сначала загружает модель из файла `../models/catboost_clf.cbm`, затем использует её для предсказания вероятностей для каждого объекта тестовых данных. Результаты сохраняются в файл `submission.csv`.

  - **Процесс работы**:
    - Обработанные тестовые данные загружаются из файла `test_processed.parquet`.
    - Модель, сохранённая после обучения (`catboost_clf.cbm`), загружается из директории `../models/`.
    - Для каждого объекта тестового набора генерируются вероятности класса.
    - Файл с предсказаниями `submission.csv` сохраняется в корне проекта и содержит два столбца: `id` и `score` (вероятность принадлежности к классу 1).
   
## Инструкция по запуску

### Требования
Для запуска проекта требуется установить зависимости, указанные в файле requirements.txt, поэтому запустите скрипт:

```bash
pip install -r requirements.txt
```

### Генерация признаков
Запустите скрипт для обработки данных и создания новых признаков:

```bash
python scripts/feature_engineering.py
```

Впоследствие его запуска в папке input/ появятся два файла, содержащие отформатированные данные:
* train_processed.parquet;
* test_processed.parquet.

### Обучение модели

После генерации признаков запустите обучение модели:

```bash
python scripts/model_training.py
```

После запуска данного скрипта в папке models появится файл catboost_clf.cbm.

### Создание файла с предсказаниями
Когда модель будет обучена, создайте файл с предсказаниями:

```bash
python scripts/generate_submission.py
```

Результатом выполнения этого скрипта будет создание файла submission.csv в корневой директории.

## Структура директории решения после запуска всех скриптов

```plaintext
vk-internship-project/
├── models/
│   └── catboost_clf.cbm      # Модель, обученная CatBoost
├── notebooks/
│   └── eda.ipynb
├── input/
│   ├── train.parquet
│   ├── test.parquet
│   ├── train_processed.parquet # Обработанный тренировочный набор данных
│   └── test_processed.parquet  # Обработанный тестовый набор данных
├── scripts/
│   ├── utils.py
│   ├── feature_engineering.py
│   ├── model_training.py
│   └── generate_submission.py
└── requirements.txt
└── submission.csv              # Файл с результатами для оценки
```
